### Explain and compare following concepts, provide specific examples when doing comparison:

#### Testing related:

#### 1. Unit Testing

- Focuses on testing **individual components** (e.g., methods, classes) in **isolation** from the rest of the system.
- Goal: Verify the internal logic of a single function or class.
- Tools: JUnit, Mockito

**Example**: Testing a `calculateTotal()` method in a shopping cart service without hitting the database.

---

#### 2. Functional Testing

- Validates that a system's **features work according to business requirements**.
- Performed from the user's perspective.
- Includes UI testing and API response checks.

**Example**: Verifying that a user can successfully log in with valid credentials.

---

#### 3. Integration Testing

- Tests how **multiple components or systems work together**.
- Ensures data flow between services, controllers, and databases is correct.

**Example**: Testing a user registration feature that involves controller → service → repository → database.

---

#### 4. Regression Testing

- Re-runs existing test cases to make sure **new code changes don't break** previously working features.

**Example**: After fixing a bug in the payment module, re-testing all cart and checkout functionalities.

---

#### 5. Smoke Testing

- A quick check to verify that the **core application features** are working.
- Done after a new build is deployed.

**Example**: Checking that the homepage loads, login works, and API endpoints are reachable right after deployment.

---

#### 6. Performance Testing

- Evaluates how well the system performs under load or stress (speed, scalability, stability).
- Types include load testing, stress testing, and endurance testing.

**Example**: Simulating 1000 concurrent users accessing a product catalog to see response times.

---

#### 7. A/B Testing

- Compares **two versions of a feature** (A vs B) to determine which one performs better based on user interaction.
- Used in product design and marketing.

**Example**: Showing two different versions of a sign-up form to see which results in more conversions.

#### 8. User Acceptance Testing (UAT)

- Final round of testing conducted by **actual users or clients**.
- Confirms the system meets their requirements before going live.

**Example**: A client tests a web app to make sure the features work as expected before final approval.

---

### Summary Table:

| Test Type           | Scope               | Purpose                               | Who Performs It          |
| ------------------- | ------------------- | ------------------------------------- | ------------------------ |
| Unit Testing        | Individual unit     | Validate internal logic               | Developers               |
| Functional Testing  | Features            | Verify business logic works           | QA/Testers               |
| Integration Testing | Components together | Validate interactions                 | Developers/Testers       |
| Regression Testing  | Whole app           | Catch new bugs from old features      | QA/Testers               |
| Smoke Testing       | Critical paths      | Ensure app is test-ready after build  | QA/Testers               |
| Performance Testing | System under load   | Test speed, stability, scalability    | QA/Performance Engineers |
| A/B Testing         | Feature variants    | Measure which version performs better | Product/Marketing Teams  |
| User Acceptance     | Full system         | Final approval by real users          | End Users / Clients      |

#### Environment related:

---

#### 1. Development Environment

- Where **developers write, test, and debug** code.
- Usually runs on local machines with mocked or lightweight services.
- Frequent code changes and restarts.

**Example**: A developer testing a new login API on `localhost:8080` before committing code.

---

#### 2. QA (Quality Assurance) Environment

- A **dedicated testing environment** used by testers to perform various tests such as functional, integration, and regression.
- More stable than development but still allows deployment of test builds.

**Example**: QA team testing user registration and cart features on a QA server before sign-off.

---

#### 3. Pre-Prod / Staging Environment

- A **mirror of the production environment**, used for final checks and validations.
- Often connected to production-like services and databases with mock or scrubbed data.
- Used for User Acceptance Testing (UAT) and final approvals.

**Example**: Business team runs UAT on staging to validate UI and workflow before go-live.

---

#### 4. Production Environment

- The **live environment** where real users interact with the application.
- Must be highly stable, monitored, and secure.
- Only thoroughly tested and approved builds are deployed here.

**Example**: A customer using the e-commerce website to place a real order.

---

### Summary Table:

| Environment      | Purpose                         | Who Uses It         | Stability |
| ---------------- | ------------------------------- | ------------------- | --------- |
| Development      | Code writing and local testing  | Developers          | Low       |
| QA               | Feature and bug testing         | Testers/QA team     | Medium    |
| Staging/Pre-prod | Final validation before release | QA + Business users | High      |
| Production       | Real user interaction           | End users           | Very High |

### 1. List and explain all of the new learned annotations to your annotations.md

### 2. What is the lifecircle of Junit?

JUnit tests follow a specific lifecycle consisting of setup, execution, and cleanup phases:

---

### 1. Setup Phase

Before tests run, JUnit prepares the environment:

- `@BeforeAll`: Runs once **before all test methods** in the class. Used for expensive setup like opening database connections.
- `@BeforeEach`: Runs **before each individual test method**. Commonly used to reset lightweight objects or test data.

---

### 2. Test Execution Phase

- The test methods run and perform **assertions**.
- This is where the actual **logic is tested**, and the outcome determines if the test **passes or fails**.

```java
@Test
void testAdd() {
    assertEquals(4, calculator.add(2, 2));
}
```

---

### 3. Cleanup Phase

After test execution, JUnit tears down the test environment:

- `@AfterEach`: Runs **after every test method** to clean up temporary data or reset states.
- `@AfterAll`: Runs **once after all tests are complete**, often used to close database connections or release resources.

---

### 3. Explain parameterized testing?

**Parameterized testing** is a technique in which the **same test method runs multiple times**, each with **different input values**. This helps you test multiple data scenarios without writing separate test methods for each case.

---

### Why Use It?

- Reduces duplicate test code
- Ensures broader test coverage with various input combinations
- Makes tests easier to maintain and scale

### 4. Explain Mockito and PowerMock .

- **Mockito** is a widely used Java mocking framework for **unit testing**.
- It allows you to create **mock objects** to simulate the behavior of real dependencies, helping you **isolate the component** under test.
- Commonly used to:
  - Stub method returns
  - Verify interactions
  - Avoid real DB/API calls

### 5. Compare @Mock and @InjectMock

### `@Mock`

- Used to create **mock objects** for classes or interfaces.
- You apply it to dependencies that you want to **simulate** in your test.

### `@InjectMocks`

- Used to create an instance of the **class under test**, and automatically **inject all `@Mock` dependencies** into it.
- It helps test the actual logic in your class while mocking its dependencies.

### 6. Explain stubbing .

**Stubbing** is the process of **defining the behavior** of a mock object in a test. It tells the mock what to return (or do) when a specific method is called with specific arguments.

Stubbing helps you:

- **Isolate the unit** under test from its real dependencies
- Simulate various scenarios (success, failure, exceptions)
- Keep tests **focused and predictable**

### 7. what is Mockito ArgumentMatchers

**Mockito ArgumentMatchers** are used to match method arguments in a **flexible way** when stubbing or verifying interactions with mock objects.

They are especially helpful when:

- You don’t care about the exact value of the argument
- The argument is dynamically generated or hard to predict

### 8. Compare @spy and @Mock?

### `@Spy`

- Creates a **partial mock** based on a real object.
- Real methods are called unless you explicitly stub them.
- Useful when you want to use the real implementation **but override specific methods**.

### `@Mock`

- Creates a **full mock** of a class or interface.
- All methods return default values (`null`, `0`, `false`, etc.) unless explicitly stubbed.
- Useful when you want to **completely control behavior** and isolate the object.

### 9. Explain Assertion .

---

**Assertions** are used in testing to **verify that the actual result matches the expected outcome**. They are the core of unit tests, ensuring that the application behaves as intended.

JUnit provides several built-in assertion methods to validate conditions.

---

### Common Assertions:

| Assertion                             | Purpose                                      |
| ------------------------------------- | -------------------------------------------- |
| `assertEquals(expected, actual)`      | Verifies that two values are equal           |
| `assertTrue(condition)`               | Checks that a condition is true              |
| `assertFalse(condition)`              | Checks that a condition is false             |
| `assertNotNull(object)`               | Ensures an object is not null                |
| `assertThrows(exception, executable)` | Verifies that a specific exception is thrown |

---

### 10. Add unit tests for CommentServiceImpl under Redbook->branch 10_testing (fork or copy the project https://github.com/CTYue/springboot-redbook),

#### 1. Enrich logics inside `CommentServiceImpl` methods, add if-else conditions in each methods.

#### 2. In `CommentServiceImpl`, add following method, remove modelMapper dependency, and replace all `modelMapper.map()` with this method, write unit test for `commentServiceMapperUtil`

#### 3. method coverage and branch coverage for CommentServiceImpl should be 100% (as much as you can), .

````public static CommentDto commentServiceMapperUtil(Comment comment) {
     ModelMapper modelMapper = new ModelMapper();
     return modelMapper.map(comment, CommentDto.class);
}```
````
