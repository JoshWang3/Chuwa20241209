Topic

A logical name representing a stream of messages.
Messages are written by producers and read by consumers.
Topics are divided into partitions for scalability.
Partition

A topic is split into multiple partitions to enable parallel processing.
Each partition is stored on different brokers.
Messages inside a partition are ordered, but across partitions, order is not guaranteed.
Broker

A Kafka server that stores partitions and serves messages to consumers.
A Kafka cluster consists of multiple brokers.
Brokers ensure fault tolerance and scalability.
Consumer Group

A group of consumers that share the same group ID.
Kafka ensures that each partition is assigned to only one consumer within a group.
This allows parallel consumption while ensuring no duplicate processing within the group.
Producer

A component that writes messages to Kafka topics.
Producers determine which partition the message should be sent to (via key-based or round-robin partitioning).
Offset

A unique identifier for each message in a partition.
Consumers keep track of offsets to resume processing after restarts or failures.
Zookeeper

Manages Kafka metadata, such as:
Broker discovery (which broker stores which partition).
Leader election (selecting which broker is responsible for a partition).
Consumer group coordination (rebalancing when consumers join or leave).



1. 
N â‰¥ M (Partitions >= Consumers):

Each consumer gets at least one partition, some may handle multiple partitions.
This ensures all partitions are actively consumed.

N < M (Partitions < Consumers):

Some consumers remain idle because a partition can only be consumed by one consumer in the same group.

2. 
Brokers store topic partitions and serve consumer requests.
Each partition has a leader broker, and others store replicas for fault tolerance.
Producers send messages to brokers, which write them to the appropriate partition.
Consumers pull messages from brokers, reading only from the assigned partitions.

3. 
Consumers pull messages from topics.
Kafka follows a pull-based model where consumers request messages at their own pace.
This ensures backpressure handling, preventing consumers from being overwhelmed.

4.
Idempotent processing: Ensure consumers can process duplicates safely.
Enable transactional producer (enable.idempotence=true) to ensure exactly-once writes.
Manually commit offsets after successful processing to avoid reprocessing on restart.

5. 
No data loss occurs.
Kafka will rebalance partitions among remaining consumers in the group.
If a consumer later recovers, it will continue processing from the last committed offset.

6.
No immediate data loss, but it depends on retention settings.
Messages remain stored in Kafka until they expire based on retention policies.
If consumers restart before data expires, they can resume from the last committed offset.

7. 
Consumer lag = Latest offset (produced) - Last committed offset (consumed).
Causes:
    Slow consumer processing.
    Network delays.
    Imbalanced partition assignments.
Resolution:
    Scale more consumers in the group.
    Optimize batch size (max.poll.records).
    Tune consumer fetch settings (fetch.max.bytes).

8.
Consumers track their offset position in a partition.
Offsets can be:
Auto-committed (not recommended due to risk of reprocessing).
Manually committed after successful processing.
If a consumer crashes, it resumes from the last committed offset.


