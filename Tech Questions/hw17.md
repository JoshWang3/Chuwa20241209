# HW16
## Questions:

### 0. Explain following concepts, and how they coordinate with each other:
Example: Uber app

1. Topic
   A topic is a category to which messages are sent by producers and from which consumers read messages. Topics are logical channels used to organize data.
    Ex: Live location updates from drivers

2. Partition
   A partition is a subset of a topic and allows Kafka to distribute messages across multiple brokers. Each partition is stored in a Kafka broker and enables parallel processing.
    Ex: Each partition stores location updates from a subset of drivers. Based on driver ID (hashing)

3. Broker
   A broker is a Kafka server that stores topic partitions and serves producer/consumer requests. Kafka clusters typically consist of multiple brokers, which work together to ensure high availability.
    Ex: Kafka brokers store driver location updates. Multiple brokers share the load, ensuring high availability.

4. Consumer Group
   A consumer group consists of multiple consumer instances that work together to read data from a topic. Each partition within a topic is assigned to one consumer in a group, ensuring load balancing.
    Ex: `passenger-apps` - Each consumer fetches driver location updates for nearby passengers.

5. Producer
   A producer is responsible for publishing messages to Kafka topics. Producers choose which partition to send data to and handle serialization.
    Ex: Each driver’s mobile app is a producer. It sends GPS location updates every few seconds.

6. Offset
   An offset is a unique identifier assigned to each message within a partition. Consumers keep track of offsets to maintain their position in the topic.
    Ex: A passenger’s app fetches updates and stores the last offset processed. If the app crashes, it can resume from the last offset.

7. Zookeeper
   Zookeeper is used to manage Kafka’s metadata, leader election, and broker coordination. It helps brokers coordinate and keep track of consumer offsets (though this has been replaced by Kafka’s internal metadata management in later versions).
    Ex: If a Kafka broker goes down, Zookeeper elects a new leader. It keeps track of which consumers are active.


### 1. Given N (partitions) and M (consumers), what happens when N >= M and N < M?
When N >= M: Each consumer gets at least one partition, and some consumers may get multiple partitions. Load is distributed.
When N < M: Some consumers will be idle since a partition can only be assigned to one consumer within a group.



### 2. Explain how brokers work with topics.
Brokers store topic partitions and manage read/write requests from producers and consumers. Each broker is responsible for some partitions and replicates data for fault tolerance.




### 3. Are messages pushed to consumers, or do consumers pull messages from topics?
Kafka uses a pull-based model, meaning consumers pull messages from brokers when ready. This prevents brokers from overwhelming consumers.



### 4. How to avoid duplicate consumption of messages?
Kafka ensures exactly-once processing by:

- Using consumer offsets stored in Kafka or external storage.
- Using idempotent producers and transactions to prevent reprocessing.




### 5. What happens if some consumers are down in a consumer group? Will data loss occur?
No data loss. Kafka will rebalance the partitions among the remaining consumers in the group. The newly assigned consumers will resume reading from the last committed offset.



### 6. What happens if an entire consumer group is down? Will data loss occur?
No data loss. Kafka retains messages for a configured retention period. Once the group restarts, consumers resume from the last committed offset.




### 7. Explain consumer lag and how to resolve it.
Consumer lag occurs when consumers fall behind producers.
How to resolve it?

- Increase consumer throughput (optimize processing).
- Scale horizontally by adding more consumers.
- Tune fetch size and batch processing.



### 8. How does Kafka track message delivery?
- Kafka tracks message offsets per consumer group.
- Consumers commit offsets manually (commitSync()) or automatically.
- Log compaction ensures messages are retained if needed.



### 9. Compare Kafka vs. RabbitMQ, messaging frameworks vs. MySQL (Why Kafka?)
- Kafka is used for Event streaming, real-time analytics, logs processing. RabbitMQ is used for Traditional messaging, request-response, job processing.
- Producers and consumers interact differently in RabbitMQ and Kafka. In RabbitMQ, the producer sends and monitors if the message reaches the intended consumer. On the other hand, Kafka producers publish messages to the queue regardless of whether consumers have retrieved them.
- Message priority: RabbitMQ brokers allow producer software to escalate certain messages by using the priority queue. Apache Kafka doesn't support priority queues. It treats all messages as equal.
- Message deletion: A RabbitMQ broker routes the message to the destination queue. Once read, the consumer sends an acknowledgement (ACK) reply to the broker, which then deletes the message from the queue. Unlike RabbitMQ, Apache Kafka appends the message to a log file, which remains until its retention period expires. That way, consumers can reprocess streamed data at any time within the stipulated period.

MySQL is database-based (polling approach) which is slower and use tables to store messages. Not optimized for high-throughput streaming. Requires manual cleanup.

### 10.
1. Write your consumer application with Spring Kafka dependency, set up 3 consumers in a single
   consumer group.
   Prove message consumption with screenshots.

    Check Coding/HW17

2. Increase number of consumers in a single consumer group, observe what happens, explain your observation.
   Assigned Partitions becomes 3, same as number of consumers. If number of consumers > number of partitions, the rest consumers will be idle

3. Create multiple consumer groups using Spring Kafka, set up different numbers of consumers within each group, observe consumer offset,
   Check Coding/HW17

4. Prove that each consumer group is consuming messages on topics as expected, take screenshots of offset records,
   Check Coding/HW17

5. Demo different message delivery guarantees in Kafka, with necessary code or configuration changes.
   At-most-once → Messages may be lost but are never duplicated.
   At-least-once → Messages are never lost but may be duplicated.
   Exactly-once → Messages are processed only once, ensuring no loss and no duplication. No duplicates due to Kafka’s idempotent producer.
   
   Check Coding/HW17








