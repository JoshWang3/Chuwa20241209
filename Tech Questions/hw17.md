### Explain following concepts, and how they coordinate with each other:
#### Topic
- Topic is essentially a named stream or feed to which records (messages) are published. It acts as a logical channel for organizing data, similar to a category or a channel in a messaging system.
#### Partition
- Partition is a subdivision of a topic. Each topic can have one or more partitions, and every record within a topic is assigned to one of its partitions.
#### Broker
- Broker is a Kafka server that is responsible for storing and serving data. In a Kafka cluster, there can be multiple brokers working together.
#### Consumer group
- Consumer group is a collection of consumers that work together to consume messages from one or more topics. Each consumer in the group is responsible for reading from a subset of partitions.
#### Producer
- Producer is an application or component that publishes data (messages) to Kafka topics.
#### Offset
- Offset is a unique identifier (typically a sequential number) assigned to each record within a partition. It indicates the position of the record in that partition.
#### Zookeeper
- Zookeeper manages and coordinates the cluster state, including broker registration, leader election, and consumer group membership.
### Answer following questions:
### 1. Given N (number of partitions) and M (number of consumers,) what will happen when N>=M and N<M respectively?
#### N≥M:
- Each consumer gets one or more partitions.
- All consumers are active, and the workload is well distributed.

#### N<M:
- Some consumers will remain idle because there aren’t enough partitions to assign.
- The consumer group’s effective parallelism is limited to the number of partitions.
### 2. Explain how brokers work with topics?
- When a producer sends a message to a topic, it connects to any broker, determines the appropriate partition using a key or round-robin strategy, and forwards the message to that partition's leader broker. 
- The leader broker then appends the message to its local disk log, while follower brokers replicate the data to ensure consistency. 
- Meanwhile, consumers connect to a broker, specify the partitions they want to consume from, and pull messages from the leader broker starting from their last recorded offset.
### 3. Are messages pushed to consumers or consumers pull messages from topics?
- In Kafka, messages are not pushed to consumers; instead, consumers pull messages from topics at their own pace.
### 4. How to avoid duplicate consumption of messages?
- Tracking all successfully consumed messages can help to avoid this scenario. This can be achieved by assigning a unique ID to every message created at the producer side (order service), and tracking them on the consumer side (fulfillment service) by storing each ID in a database table (Message ID Tracking Table).
### 5. What will happen if some consumers are down in a consumer group? Will data loss occur? Why?
- If some consumers within a consumer group go down, Kafka's design—including durable storage, offset management, and consumer group rebalancing—ensures that no data is lost. The remaining consumers take over the processing of the affected partitions, and once the downed consumers recover, they can rejoin the group and resume processing from the correct offsets.
### 6. What will happen if an entire consumer group is down? Will data loss occur? Why?
- If an entire consumer group goes down, the messages remain safely stored in Kafka. Once the consumer group recovers, it can resume processing from the last committed offset, ensuring that no data is lost.
### 7. Explain consumer lag and how to resolve it?
- **"Consumer lag"** refers to the delay between when a message is produced by a producer and when it is consumed by a consumer, essentially measuring how far behind a consumer is in processing messages within a topic.
### How to resolve it:
- Monitor consumer lag
- Optimize consumer processing
- Adjust consumer group configuration
- Manage producer rate
- Enhance Infrastructure
- Handle failures gracefully
### 8. Explain how Kafka tracks message delivery?
- Kafka tracks message delivery by assigning a unique identifier called an "offset" to each message within a partition of a topic, essentially acting like a sequential number in an ordered log
### 9. Compare Kafka vs RabbitMQ, compare messageing frameworks vs MySql (Why Kafka)?
#### Kafka vs. RabbitMQ:
- Kafka is optimized for high-throughput, scalable event streaming with a durable log-based architecture and pull-based consumption. RabbitMQ excels in flexible messaging patterns with low-latency push-based delivery and complex routing capabilities.

#### Messaging Frameworks vs. MySQL (Why Kafka):
- Kafka is chosen over MySQL for messaging because it is engineered for real-time data ingestion, processing, and event streaming at scale. MySQL, being a relational database, is best for transactional data management and structured queries rather than continuous high-volume message flows.
### 10. On top of https://github.com/CTYue/Spring-Producer-Consumer Write your consumer application with Spring Kafka dependency, set up 3 consumers in a single consumer group.
### Prove message consumption with screenshots.Increase number of consumers in a single consumer group, observe what happens, explain your observation.Create multiple consumer groups using Spring Kafka, set up different numbers of consumers within each group, observe consumer offset,
### Prove that each consumer group is consuming messages on topics as expected, take screenshots of offset records,Demo different message delivery guarantees in Kafka, with necessary code or configuration changes.
### Note: There's already a docker compose file in above git repo, you can start the 3 brokers (with zookeep) using docker-compose up command.