# Homework 17

## 0. Explain following concepts, and how they coordinate with each other:
```
Topic
Partition
Broker
Consumer group
Producer
Offset
Zookeeper
```

**Topic**  
Logical channel for data categorization. Split into **partitions** for scalability and parallel processing.

**Partition**  
Ordered, immutable data subset within a topic. Enables parallelism and load distribution across brokers.

**Broker**  
Kafka server/node storing partitions. Forms a distributed cluster for fault tolerance and scalability.

**Consumer Group**  
Set of consumers sharing a group ID. Each partition is consumed by only one consumer in the group (parallelism).

**Producer**  
Publishes data to topics. Routes messages to partitions (round-robin, key-based hashing).

**Offset**  
Unique ID for messages in a partition. Tracks consumer progress (per partition) for at-least-once delivery.

**Zookeeper**  
Centralized metadata/coordination service (legacy). Manages broker registration, leader election, and consumer offsets (pre-Kafka 2.8). Replaced by **KRaft** (self-managed metadata) in newer versions.

---

### Coordination Flow

1. **Producers** publish data to **topic partitions** via brokers.  
2. **Brokers** distribute partitions across the cluster (replication for fault tolerance).  
3. **Consumer groups** subscribe to topics; each consumer reads from assigned partitions.  
4. **Offsets** track progress per partition to avoid reprocessing.  
5. **Zookeeper/KRaft** coordinates brokers (leader election, metadata sync) and tracks consumer offsets (legacy).  

**Key Relationships**:  
- Topics → Partitions → Brokers (storage).  
- Producers → Brokers (write).  
- Consumer Groups → Partitions (read).  
- Offsets → Consumer Groups (progress tracking).  
- Zookeeper/KRaft → Cluster coordination (metadata, health).  



## 1. Given N (number of partitions) and M (number of consumers,) what will happen when N>=M and N<M respectively?
**Case 1: N ≥ M**  
- **All consumers are active**.  
- Each consumer handles `ceil(N/M)` partitions (balanced distribution).  
- **Max parallelism = N** (limited by partitions).  

**Case 2: N < M**  
- **Only N consumers are active** (1 partition each).  
- `M - N` consumers remain **idle** (no partitions to consume).  
- **Max parallelism = N** (fixed by partition count).  

**Key Insight**:  
- **Partitions dictate max parallelism** in a consumer group.  
- Excess consumers (beyond partition count) are unused. 

## 2. Explain how brokers work with topics?
1. **Storage**:  
   - Brokers host **topic partitions** (physical storage units).  
   - Each partition is assigned to a broker (leader) and replicated to others (followers).  

2. **Replication**:  
   - Brokers maintain **replica partitions** for fault tolerance (leader handles writes/reads; followers sync data).  

3. **Load Balancing**:  
   - Partitions are distributed across brokers to balance storage and I/O.  

4. **Metadata Management**:  
   - Brokers track topic/partition metadata (e.g., leader info, offsets) via **Zookeeper/KRaft**.  

5. **Request Handling**:  
   - Brokers serve **producer writes** (to partition leaders) and **consumer reads** (from leader/followers).  

**Summary**: Brokers physically store and manage topic data, ensuring scalability, redundancy, and data access.   


## 3. Are messages pushed to consumers or consumers pull messages from topics?

**Pull-based**:  
- **Consumers actively request (poll)** messages from brokers.  
- **Advantages**:  
  - Consumers control consumption rate (avokes overload).  
  - Enables batch processing and offset management.  

**No push**: Brokers never push data to consumers. 

## 4. How to avoid duplicate consumption of messages? 
1. **Offset Management**:  
   - Consumers commit **offsets** only *after* processing messages (at-least-once semantics).  

2. **Idempotent Processing**:  
   - Design consumers to handle duplicates safely (e.g., checks like "has this ID been processed?").  

3. **Exactly-Once Semantics**:  
   - Use Kafka transactions (producer-consumer coordination) for end-to-once guarantees.  

**Note**: Network failures/retries may still cause duplicates; idempotency is critical.   

## 5. What will happen if some consumers are down in a consumer group? Will data loss occur? Why?
1. **No Data Loss**:  
   - Kafka stores messages in **persistent brokers** (not tied to consumers).  

2. **Rebalance**:  
   - Surviving consumers reassign the failed consumer's partitions (via group coordinator).  

3. **Offset Tracking**:  
   - New consumers resume from the last **committed offset** (no gaps).  

**Why No Loss?**  
Messages remain on brokers until retention expires. Failures affect *processing*, not *data integrity*.  

## 6. What will happen if an entire consumer group is down? Will data loss occur? Why? 
1. **No Immediate Data Loss**:  
   - Messages remain stored in **brokers** (based on retention period).  

2. **Processing Halt**:  
   - No progress in consuming new messages until the group restarts.  

3. **Risk of Data Loss**:  
   - **Only if retention expires** (messages deleted before group resumes).  

**Why?**  
Kafka decouples storage (brokers) from consumption (groups). Data loss depends on retention, not consumer availability.  

## 7. Explain consumer lag and how to resolve it?
**Consumer Lag**:  
Difference between latest message offset (produced) and last committed offset (consumed). Indicates processing delay.

**Resolution**:  
1. **Scale Consumers**: Add more consumers (up to partition count).  
2. **Optimize Throughput**:  
   - Tune consumer `fetch.max.bytes`, `max.poll.records`.  
   - Parallelize processing (per message/thread).  
3. **Monitor**: Track lag via metrics (e.g., `kafka-consumer-groups` CLI).  
4. **Autoscale**: Dynamically adjust consumer instances based on lag.  
5. **Increase Partitions**: If lag persists, expand partitions (requires reprocessing).  

**Key**: Balance consumer capacity with producer load.   


## 8. Explain how Kafka tracks message delivery?
1. **Offsets**:  
   - Each message has a unique **offset** per partition.  
   - Consumers track progress via **committed offsets** (last processed message).  

2. **Consumer Groups**:  
   - Offsets are stored in Kafka (__consumer_offsets topic) or Zookeeper (legacy).  

3. **Delivery Semantics**:  
   - **At-least-once**: Offsets committed *after* processing (possible duplicates).  
   - **Exactly-once**: Uses transactions (producer/consumer IDs, atomic commits).  

4. **Broker Role**:  
   - Brokers retain messages until retention expires, allowing consumers to reprocess if needed.  

**Tracking Flow**: Offsets + consumer group coordination ensure delivery status visibility.  
 

## 9. Compare Kafka vs RabbitMQ, compare messageing frameworks vs MySql (Why Kafka)
### Kafka vs RabbitMQ

| **Aspect**          | **Kafka**                          | **RabbitMQ**                     |
|----------------------|------------------------------------|----------------------------------|
| **Design**           | Distributed log (streaming)       | Traditional message broker       |
| **Throughput**       | High (scales horizontally)        | Moderate (per-queue scaling)     |
| **Persistence**      | Long-term retention (disk-based)  | Transient (memory/disk, acked)   |
| **Use Case**         | Event streaming, real-time pipelines | Task queues, RPC, complex routing |
| **Delivery**         | Pull-based (consumers control)    | Push-based (broker pushes)       |

---

### Messaging Frameworks (Kafka) vs MySQL

| **Aspect**          | **Kafka**                          | **MySQL**                        |
|----------------------|------------------------------------|----------------------------------|
| **Purpose**          | Real-time data streaming          | Structured data storage/querying |
| **Data Model**       | Append-only logs (immutable)      | Tables with CRUD operations      |
| **Throughput**       | Optimized for high write/read     | Optimized for transactional OLTP |
| **Scalability**      | Horizontal (partition-based)      | Vertical + limited horizontal    |
| **Why Kafka?**       | Decouple producers/consumers, handle massive event streams, replayability | Use for ACID transactions, complex queries, relational data |




























